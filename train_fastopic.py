#!/usr/bin/env python3
"""
FASTopicè®­ç»ƒè„šæœ¬
ä¸“é—¨ç”¨äºåŠ è½½å·²æœ‰çš„cell embeddingsè®­ç»ƒscFASTopicæ¨¡å‹
"""
import os
import argparse
import numpy as np
import pandas as pd
import torch
import scipy.sparse as sp
from pathlib import Path
import pickle
import json
import time
from typing import Optional, List, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# å¯è§†åŒ–ç›¸å…³å¯¼å…¥
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import umap


# ä½¿ç”¨è‡ªå®šä¹‰çš„utilså‡½æ•°
def save_matrices(matrices, dataset_name, n_topics, output_dir):
    """ä¿å­˜çŸ©é˜µåˆ°æŒ‡å®šç›®å½•"""
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    saved_files = []
    for matrix_name, matrix in matrices.items():
        filename = f"{dataset_name}_{matrix_name}_{n_topics}.pkl"
        filepath = output_dir / filename
        
        with open(filepath, 'wb') as f:
            pickle.dump(matrix, f)
        
        saved_files.append(str(filepath))
        print(f"ğŸ’¾ Saved {matrix_name}: {filepath}")
    
    return saved_files

def calculate_topic_metrics(cell_topic_matrix):
    """è®¡ç®—topicè´¨é‡æŒ‡æ ‡"""
    from scipy.stats import entropy
    
    # å¤„ç†NaNå€¼
    if np.isnan(cell_topic_matrix).any():
        print("âš ï¸ Warning: Found NaN values in cell-topic matrix for metrics calculation")
        cell_topic_matrix = np.nan_to_num(cell_topic_matrix, nan=0.0)
    
    topic_weights = cell_topic_matrix.mean(axis=0)
    shannon_entropy = entropy(topic_weights + 1e-12, base=2)
    effective_topics = 2**shannon_entropy
    dominant_topic_ratio = topic_weights.max() * 100
    
    return {
        'shannon_entropy': shannon_entropy,
        'effective_topics': effective_topics,
        'dominant_topic_ratio': dominant_topic_ratio,
        'topic_weights': topic_weights
    }

def create_summary_report(matrices, metrics, dataset_name, n_topics):
    """åˆ›å»ºæ‘˜è¦æŠ¥å‘Š"""
    report = f"""# scFASTopic Training Report

## Dataset Information
- Dataset: {dataset_name}
- Number of topics: {n_topics}
- Number of cells: {matrices['cell_embeddings'].shape[0]:,}
- Number of genes: {matrices['topic_gene_matrix'].shape[1]:,}

## Model Performance
- Shannon Entropy: {metrics['shannon_entropy']:.3f}
- Effective Topics: {metrics['effective_topics']:.1f}
- Dominant Topic Ratio: {metrics['dominant_topic_ratio']:.1f}%

## Matrix Shapes
- Cell embeddings: {matrices['cell_embeddings'].shape}
- Cell-topic matrix: {matrices['cell_topic_matrix'].shape}
- Topic-gene matrix: {matrices['topic_gene_matrix'].shape}
"""
    return report

def validate_matrices(matrices):
    """éªŒè¯çŸ©é˜µå½¢çŠ¶å’Œå†…å®¹"""
    try:
        for name, matrix in matrices.items():
            if matrix is None:
                print(f"âš ï¸ Warning: {name} is None")
                return False
            if matrix.size == 0:
                print(f"âš ï¸ Warning: {name} is empty")
                return False
        return True
    except Exception as e:
        print(f"âŒ Matrix validation error: {e}")
        return False


class FastopicConfig:
    """FASTopicè®­ç»ƒé…ç½®ç±»"""
    
    def __init__(self):
        # è¾“å…¥è¾“å‡º
        self.embedding_file = None
        self.genes_file = None
        self.dataset = 'PBMC'
        self.output_dir = 'results'
        self.visualization_dir = 'visualization'
        
        # æ¨¡å‹å‚æ•°
        self.n_topics = 20
        self.epochs = 100
        self.learning_rate = 0.01
        
        # FASTopicè¶…å‚æ•°
        self.DT_alpha = 1.0
        self.TW_alpha = 1.0
        self.theta_temp = 2.0
        
        # å…¶ä»–å‚æ•°
        self.verbose = True
        self.seed = 42


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Train scFASTopic with pre-extracted cell embeddings')
    
    # è¾“å…¥æ–‡ä»¶å‚æ•°
    parser.add_argument('--embedding_file', type=str, required=True,
                       help='Path to cell embeddings pkl file')
    parser.add_argument('--genes_file', type=str, required=True,
                       help='Path to selected genes pkl file')
    parser.add_argument('--dataset', type=str, default='PBMC',
                       help='Dataset name')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output_dir', type=str, default='results',
                       help='Output directory')
    parser.add_argument('--viz_dir', type=str, default='visualization',
                       help='Visualization directory')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--n_topics', type=int, default=20,
                       help='Number of topics')
    parser.add_argument('--epochs', type=int, default=100,
                       help='Training epochs')
    parser.add_argument('--lr', type=float, default=0.01,
                       help='Learning rate')
    
    # FASTopicè¶…å‚æ•°
    parser.add_argument('--DT_alpha', type=float, default=1.0,
                       help='Dirichlet-tree alpha parameter')
    parser.add_argument('--TW_alpha', type=float, default=1.0,
                       help='Topic-word alpha parameter')
    parser.add_argument('--theta_temp', type=float, default=2.0,
                       help='Temperature parameter')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed')
    parser.add_argument('--quiet', action='store_true',
                       help='Quiet mode')
    
    return parser.parse_args()


def load_embeddings_and_genes(embedding_file: str, genes_file: str, bow_file: str = None, verbose: bool = False):
    """
    åŠ è½½cell embeddingsã€åŸºå› åˆ—è¡¨å’ŒBOWçŸ©é˜µ
    
    Args:
        embedding_file: cell embeddingsæ–‡ä»¶è·¯å¾„
        genes_file: åŸºå› åˆ—è¡¨æ–‡ä»¶è·¯å¾„
        bow_file: åŸºå› è¡¨è¾¾BOWçŸ©é˜µæ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        
    Returns:
        cell_embeddings: Cell embeddingsçŸ©é˜µ
        selected_genes: åŸºå› åˆ—è¡¨
        expression_bow: åŸºå› è¡¨è¾¾BOWçŸ©é˜µ
    """
    if verbose:
        print("ğŸ“¥ Loading pre-extracted embeddings and genes")
        print("="*60)
    
    # åŠ è½½cell embeddings
    if verbose:
        print(f"ğŸ“ Loading cell embeddings: {embedding_file}")
    
    with open(embedding_file, 'rb') as f:
        cell_embeddings = pickle.load(f)
    
    # åŠ è½½åŸºå› åˆ—è¡¨
    if verbose:
        print(f"ğŸ“ Loading genes: {genes_file}")
    
    with open(genes_file, 'rb') as f:
        selected_genes = pickle.load(f)
    
    # åŠ è½½åŸºå› è¡¨è¾¾BOWçŸ©é˜µï¼ˆå¦‚æœæä¾›ï¼‰
    expression_bow = None
    if bow_file and os.path.exists(bow_file):
        if verbose:
            print(f"ğŸ“ Loading expression BOW: {bow_file}")
        with open(bow_file, 'rb') as f:
            expression_bow = pickle.load(f)
        if verbose:
            print(f"âœ… Expression BOW: {expression_bow.shape}, ç¨€ç–åº¦: {1 - expression_bow.nnz / (expression_bow.shape[0] * expression_bow.shape[1]):.3f}")
    
    if verbose:
        print(f"âœ… Cell embeddings: {cell_embeddings.shape}")
        print(f"âœ… Selected genes: {len(selected_genes)}")
    
    return cell_embeddings, selected_genes, expression_bow


def train_fastopic_model(cell_embeddings: np.ndarray, 
                        selected_genes: List[str],
                        expression_bow,
                        config: FastopicConfig,
                        verbose: bool = False):
    """
    è®­ç»ƒscFASTopicæ¨¡å‹
    
    Args:
        cell_embeddings: Cell embeddingsçŸ©é˜µ
        selected_genes: åŸºå› åˆ—è¡¨
        config: é…ç½®å‚æ•°
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        
    Returns:
        results: è®­ç»ƒç»“æœå­—å…¸
        training_time: è®­ç»ƒæ—¶é—´
    """
    if verbose:
        print("\nğŸ¤– Training scFASTopic model")
        print("="*60)
    
    # ä½¿ç”¨çœŸæ­£çš„FASTopic
    from fastopic import FASTopic
    
    model = FASTopic(
        num_topics=config.n_topics,
        device="cuda" if torch.cuda.is_available() else "cpu",
        DT_alpha=config.DT_alpha,
        TW_alpha=config.TW_alpha,
        theta_temp=config.theta_temp,
        verbose=verbose,
        log_interval=10,
        low_memory=True,                    # å¼€å¯ä½å†…å­˜æ¨¡å¼
        low_memory_batch_size=4000          # è®¾ç½®æ‰¹æ¬¡å¤§å°ä¸º1000
    )
    
    # è®­ç»ƒæ¨¡å‹
    start_time = time.time()
    if verbose:
        print(f"ğŸ”¥ Training with {config.n_topics} topics for {config.epochs} epochs...")
    
    top_words, train_theta = model.fit_transform_sc(
        cell_embeddings=cell_embeddings,
        gene_names=selected_genes,
        expression_bow=expression_bow,
        epochs=config.epochs,
        learning_rate=config.learning_rate
    )
    
    training_time = time.time() - start_time
    
    # è·å–ç»“æœçŸ©é˜µ
    beta = model.get_beta()  # topic-gene matrix
    theta = train_theta      # cell-topic matrix
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    from scipy.stats import entropy
    
    # Shannonç†µï¼ˆè¡¡é‡topicåˆ†å¸ƒçš„å‡åŒ€æ€§ï¼‰
    topic_weights = theta.mean(axis=0)
    shannon_entropy = entropy(topic_weights + 1e-12, base=2)
    
    # æœ‰æ•ˆtopicæ•°é‡
    effective_topics = 2**shannon_entropy
    
    # ä¸»å¯¼topicå æ¯”
    max_topic_weight = topic_weights.max()
    dominant_topic_ratio = max_topic_weight * 100
    
    results = {
        'beta': beta,
        'theta': theta,
        'top_words': top_words,
        'shannon_entropy': shannon_entropy,
        'effective_topics': effective_topics,
        'dominant_topic_ratio': dominant_topic_ratio,
        'model': model
    }
    
    if verbose:
        print(f"âœ… Training completed in {training_time:.1f} seconds")
        print(f"ğŸ“Š Shannon Entropy: {shannon_entropy:.3f}")
        print(f"ğŸ¯ Effective Topics: {effective_topics:.1f}")
        print(f"ğŸ‘‘ Dominant Topic: {dominant_topic_ratio:.1f}%")
    
    return results, training_time


def save_all_matrices(results: dict,
                     cell_embeddings: np.ndarray,
                     config: FastopicConfig,
                     verbose: bool = False):
    """ä¿å­˜æ‰€æœ‰çŸ©é˜µ"""
    if verbose:
        print("\nğŸ’¾ Saving matrices")
        print("="*60)
    
    # å‡†å¤‡æ‰€æœ‰çŸ©é˜µ
    matrices = {
        'cell_embeddings': cell_embeddings,
        'cell_topic_matrix': results['theta'],  # FASTopicè¿”å›çš„cell-topicçŸ©é˜µ
        'topic_gene_matrix': results['beta'],   # FASTopicè¿”å›çš„topic-geneçŸ©é˜µ
        'gene_embeddings': results['model'].word_embeddings,  # ä»æ¨¡å‹è·å–åŸºå› åµŒå…¥
        'topic_embeddings': results['model'].topic_embeddings  # ä»æ¨¡å‹è·å–ä¸»é¢˜åµŒå…¥
    }
    
    # éªŒè¯çŸ©é˜µ
    if not validate_matrices(matrices):
        raise ValueError("Matrix validation failed")
    
    # ä¿å­˜çŸ©é˜µ
    saved_files = save_matrices(
        matrices=matrices,
        dataset_name=config.dataset,
        n_topics=config.n_topics,
        output_dir=config.output_dir
    )
    
    return saved_files, matrices


def create_visualizations(results: dict, config: FastopicConfig, verbose: bool = False):
    """åˆ›å»ºå¯è§†åŒ–"""
    if verbose:
        print("\nğŸ¨ Creating visualizations")
        print("="*60)
    
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        viz_dir = Path(config.visualization_dir)
        viz_dir.mkdir(exist_ok=True)
        
        # è·å–cell-topicçŸ©é˜µ
        if verbose:
            print("ğŸ“ Creating cell-topic visualizations with cell type annotation...")
        cell_topic_matrix = results['theta']
        
        # æ£€æŸ¥å¹¶å¤„ç†NaNå€¼
        if np.isnan(cell_topic_matrix).any():
            if verbose:
                print("âš ï¸ Warning: Found NaN values in cell-topic matrix, replacing with zeros")
            cell_topic_matrix = np.nan_to_num(cell_topic_matrix, nan=0.0)
        
        # åŠ è½½ç»†èƒç±»å‹ä¿¡æ¯
        try:
            adata = sc.read_h5ad('/autodl-fs/data/dataset/PBMC.h5ad')
            sc.pp.filter_cells(adata, min_genes=200)
            sc.pp.filter_genes(adata, min_cells=3)
            cell_types = adata.obs['scType_celltype'].values[:cell_topic_matrix.shape[0]]
            cell_type_simple = adata.obs['cell_type'].values[:cell_topic_matrix.shape[0]]
            
            if verbose:
                print(f"âœ… Loaded cell types for {len(cell_types)} cells")
        except:
            cell_types = None
            cell_type_simple = None
            if verbose:
                print("âš ï¸ Could not load cell type information, using default colors")
        
        # UMAPé™ç»´cell-topicçŸ©é˜µ
        reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)
        embedding = reducer.fit_transform(cell_topic_matrix)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle(f'Cell-Topic Analysis ({config.dataset}-{config.n_topics} topics)', 
                    fontsize=16, fontweight='bold')
        
        # å›¾1: Cell-Topic UMAP (æŒ‰ç®€åŒ–cell typeæŸ“è‰²)
        ax1 = axes[0]
        if cell_type_simple is not None:
            unique_simple_types = pd.Series(cell_type_simple).unique()
            colors_simple = plt.cm.tab10(np.linspace(0, 1, len(unique_simple_types)))
            color_map_simple = dict(zip(unique_simple_types, colors_simple))
            
            for cell_type in unique_simple_types:
                mask = cell_type_simple == cell_type
                ax1.scatter(embedding[mask, 0], embedding[mask, 1], 
                           c=[color_map_simple[cell_type]], label=cell_type, alpha=0.6, s=1)
            
            ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
            ax1.set_title('Cell-Topic UMAP (by Cell Type)', fontsize=14, fontweight='bold')
        else:
            ax1.scatter(embedding[:, 0], embedding[:, 1], alpha=0.6, s=1, c='steelblue')
            ax1.set_title('Cell-Topic UMAP', fontsize=14, fontweight='bold')
        
        ax1.set_xlabel('UMAP 1')
        ax1.set_ylabel('UMAP 2')
        
        # å›¾2: æ¯ä¸ªç»†èƒç±»å‹çš„å¹³å‡topicåˆ†å¸ƒçƒ­å›¾
        ax2 = axes[1]
        if cell_type_simple is not None:
            # è®¡ç®—æ¯ä¸ªç»†èƒç±»å‹çš„å¹³å‡topicåˆ†å¸ƒ
            cell_type_topic_means = []
            cell_type_labels = []
            
            for cell_type in unique_simple_types[:8]:  # æ˜¾ç¤ºå‰8ä¸ªæœ€å¸¸è§çš„ç±»å‹
                mask = cell_type_simple == cell_type
                if np.sum(mask) > 100:  # åªåŒ…å«è¶³å¤Ÿç»†èƒæ•°çš„ç±»å‹
                    mean_topics = cell_topic_matrix[mask].mean(axis=0)
                    cell_type_topic_means.append(mean_topics)
                    cell_type_labels.append(cell_type.replace(', ', '\n'))
            
            if cell_type_topic_means:
                cell_type_topic_means = np.array(cell_type_topic_means)
                
                # åˆ›å»ºçƒ­å›¾
                sns.heatmap(cell_type_topic_means, 
                           xticklabels=[f'T{i}' for i in range(cell_topic_matrix.shape[1])],
                           yticklabels=cell_type_labels,
                           cmap='YlOrRd', ax=ax2, 
                           cbar_kws={'label': 'Average Topic Weight'})
                ax2.set_title('Average Topic Distribution by Cell Type', fontsize=14, fontweight='bold')
                ax2.set_xlabel('Topics')
                ax2.set_ylabel('Cell Types')
        else:
            # å¦‚æœæ²¡æœ‰ç»†èƒç±»å‹ä¿¡æ¯ï¼Œæ˜¾ç¤ºæ€»ä½“topicåˆ†å¸ƒ
            topic_weights = cell_topic_matrix.mean(axis=0)
            ax2.bar(range(len(topic_weights)), topic_weights, color='steelblue')
            ax2.set_title('Average Topic Distribution', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Topics')
            ax2.set_ylabel('Average Weight')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        umap_filename = viz_dir / f"{config.dataset}_cell_topic_celltype_{config.n_topics}.png"
        plt.savefig(umap_filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        if verbose:
            print(f"âœ… Cell-topic visualization saved: {umap_filename}")
        
        return [str(umap_filename)]
        
    except ImportError:
        if verbose:
            print("âš ï¸ UMAP not available, skipping visualization")
        return []


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ scFASTopic Training Pipeline")
    print("="*80)
    
    # è§£æå‚æ•°
    args = parse_args()
    
    # åˆ›å»ºé…ç½®
    config = FastopicConfig()
    
    # æ›´æ–°é…ç½®
    config.embedding_file = args.embedding_file
    config.genes_file = args.genes_file
    config.dataset = args.dataset
    config.output_dir = args.output_dir
    config.visualization_dir = args.viz_dir
    config.n_topics = args.n_topics
    config.epochs = args.epochs
    config.learning_rate = args.lr
    config.DT_alpha = args.DT_alpha
    config.TW_alpha = args.TW_alpha
    config.theta_temp = args.theta_temp
    config.verbose = not args.quiet
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    if config.verbose:
        print(f"ğŸ“Š Configuration:")
        print(f"  Dataset: {config.dataset}")
        print(f"  Topics: {config.n_topics}")
        print(f"  Epochs: {config.epochs}")
        print(f"  Learning Rate: {config.learning_rate}")
        print(f"  Embedding file: {config.embedding_file}")
        print(f"  Genes file: {config.genes_file}")
    
    try:
        # Step 1: åŠ è½½embeddingsã€åŸºå› å’ŒBOWçŸ©é˜µ
        # è‡ªåŠ¨æ¨æ–­BOWæ–‡ä»¶è·¯å¾„
        bow_file = config.embedding_file.replace('_cell_embeddings.pkl', '_expression_bow.pkl')
        cell_embeddings, selected_genes, expression_bow = load_embeddings_and_genes(
            config.embedding_file, config.genes_file, bow_file, config.verbose
        )
        
        # Step 2: è®­ç»ƒæ¨¡å‹
        results, training_time = train_fastopic_model(
            cell_embeddings, selected_genes, expression_bow, config, config.verbose
        )
        
        # Step 3: ä¿å­˜çŸ©é˜µ
        saved_files, matrices = save_all_matrices(
            results, cell_embeddings, config, config.verbose
        )
        
        # Step 4: åˆ›å»ºå¯è§†åŒ–
        viz_files = create_visualizations(results, config, config.verbose)
        
        # Step 5: è®¡ç®—æŒ‡æ ‡å’Œç”ŸæˆæŠ¥å‘Š
        metrics = calculate_topic_metrics(results['theta'])
        
        # åˆ›å»ºæŠ¥å‘Š
        report = create_summary_report(
            matrices=matrices,
            metrics=metrics,
            dataset_name=config.dataset,
            n_topics=config.n_topics
        )
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path(config.output_dir) / f"{config.dataset}_fastopic_report_{config.n_topics}.md"
        with open(report_file, 'w') as f:
            f.write(report)
        
        print(f"\nğŸ‰ Training completed successfully!")
        print(f"ğŸ“ Results saved to: {config.output_dir}/")
        print(f"ğŸ–¼ï¸ Visualizations saved to: {config.visualization_dir}/")
        print(f"ğŸ“„ Report saved to: {report_file}")
        
        print(f"\nğŸ¯ Final Results:")
        print(f"  Shannon Entropy: {results['shannon_entropy']:.3f}")
        print(f"  Effective Topics: {results['effective_topics']:.1f}")
        print(f"  Training Time: {training_time:.1f}s")
        
    except Exception as e:
        print(f"âŒ Error during training: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())